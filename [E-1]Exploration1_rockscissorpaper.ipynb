{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "incorrect-poster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-venture",
   "metadata": {},
   "source": [
    "### 1. make a function for image resizing (preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cordless-figure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599  images to be resized.\n",
      "599  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-taylor",
   "metadata": {},
   "source": [
    "Also resize images of rocks, and papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "final-worship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599  images to be resized.\n",
      "599  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "599  images to be resized.\n",
      "599  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path2)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "image_dir_path3 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path3)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adapted-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599  images to be resized.\n",
      "599  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path3 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "\n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path3)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-drive",
   "metadata": {},
   "source": [
    "1) make a tensor which consists of zero, and it is the 'white space' that image and label data will written\n",
    "2) scissor, rock, paper corresponds to 0, 1 ,2 each in label data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "offensive-reading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1797 입니다.\n",
      "x_train shape: (1797, 28, 28, 3)\n",
      "y_train shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path,1797)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-phone",
   "metadata": {},
   "source": [
    "### Make a sequntial model( neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "# MAX = np.max(x_train)\n",
    "# MIN = np.min(x_train)\n",
    "# x_train_norm = (x_train - MIN)/(MAX-MIN)\n",
    "# print(np.max(x_train_norm), np.min(x_train_norm))\n",
    "x_train_norm = x_train/255\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "print(x_train_norm.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-europe",
   "metadata": {},
   "source": [
    "### Compiling, and fitting(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "expected-centre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "57/57 [==============================] - 2s 34ms/step - loss: 1.0594 - accuracy: 0.4465\n",
      "Epoch 2/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8144 - accuracy: 0.6440\n",
      "Epoch 3/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.8323\n",
      "Epoch 4/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.8179\n",
      "Epoch 5/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8504\n",
      "Epoch 6/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.9080\n",
      "Epoch 7/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2130 - accuracy: 0.9275\n",
      "Epoch 8/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9341\n",
      "Epoch 9/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9611\n",
      "Epoch 10/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9861\n",
      "Epoch 11/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9813\n",
      "Epoch 12/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9864\n",
      "Epoch 13/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9931\n",
      "Epoch 14/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9937\n",
      "Epoch 15/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9982\n",
      "Epoch 16/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9973\n",
      "Epoch 17/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9994\n",
      "Epoch 18/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9998\n",
      "Epoch 19/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9961\n",
      "Epoch 23/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f61437a0750>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss = 'sparse_categorical_crossentropy', metrics =['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-fortune",
   "metadata": {},
   "source": [
    "### open a test dataset(also preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "smooth-transformation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33  images to be resized.\n",
      "33  images resized.\n",
      "33  images to be resized.\n",
      "33  images resized.\n",
      "33  images to be resized.\n",
      "33  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 99 입니다.\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f616f45a5d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "\n",
    "image_dir_path_1 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/test/rock\"\n",
    "image_dir_path_2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/test/scissor\"\n",
    "image_dir_path_3 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/test/paper\"\n",
    "resize_images(image_dir_path_1)\n",
    "resize_images(image_dir_path_2)\n",
    "resize_images(image_dir_path_3) \n",
    "\n",
    "image_dir_path_ = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/test\"\n",
    "\n",
    "(x_test, y_test)=load_data(image_dir_path_,number_of_data=99)\n",
    "\n",
    "x_test_norm = x_test/255\n",
    "print(np.max(x_test_norm))\n",
    "\n",
    "plt.imshow(x_test_norm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-cleaning",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "curious-chick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3573 - accuracy: 0.6364\n",
      "test loss, test acc: [1.3573217391967773, 0.6363636255264282]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test_norm, y_test, batch_size=20)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-neighbor",
   "metadata": {},
   "source": [
    "### Accuracy measured with about 64%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
