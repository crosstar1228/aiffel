{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "personal-costs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['At first I was afraid', 'I was petrified', 'I kept thinking I could never live without you']\n",
      "['I would have made you leave your key', 'If I had known for just one second', \"You'd be back to bother me Well now go,\", 'Walk out the door', 'Just turn around', \"Now, you're not welcome anymore Weren't you the one\", 'Who tried to break me with desire?', \"Did you think I'd crumble?\", \"Did you think I'd lay down and die? Oh not I,\", 'I will survive']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "txt_file_path = os.getenv('HOME') + '/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])\n",
    "print(raw_corpus[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-florence",
   "metadata": {},
   "source": [
    "Step 3. 데이터 정제\n",
    "앞서 배운 테크닉들을 활용해 문장 생성에 적합한 모양새로 데이터를 정제하세요!\n",
    "\n",
    "preprocess_sentence() 함수를 만든 것을 기억하시죠? 이를 활용해 데이터를 정제하도록 하겠습니다.\n",
    "\n",
    "추가로 지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거합니다. 너무 긴 문장은 노래 가사 작사하기에 어울리지 않을 수도 있겠죠.\n",
    "그래서 이번에는 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하기 를 권합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inclusive-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You'd be back to bother me Well now go,\n"
     ]
    }
   ],
   "source": [
    "line1 = raw_corpus[12]\n",
    "print(line1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "legendary-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(line):\n",
    "    line = line.lower().strip()\n",
    "    line = re.sub(r\"([?!,.¿])\", r\" \\1 \", line)\n",
    "    line = re.sub(r'[\" \"]+', r\" \",line)\n",
    "    line = re.sub(r\"[^a-zA-Z?!,.¿]+\", r\" \", line)\n",
    "    line = line.strip()\n",
    "    line = '<start> ' + line + ' <end>'\n",
    "    return line\n",
    "#print(preprocess_sentence(line1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hairy-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<start> at first i was afraid <end>',\n",
       " '<start> i was petrified <end>',\n",
       " '<start> i kept thinking i could never live without you <end>',\n",
       " '<start> by my side but then i spent so many nights <end>',\n",
       " '<start> just thinking how you ve done me wrong <end>',\n",
       " '<start> i grew strong <end>',\n",
       " '<start> i learned how to get along and so you re back <end>',\n",
       " '<start> from outer space <end>',\n",
       " '<start> i just walked in to find you <end>',\n",
       " '<start> here without that look upon your face i should have changed that fucking lock <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "print(len(raw_corpus))\n",
    "\n",
    "for i in raw_corpus :\n",
    "    if len(i) == 0:\n",
    "        continue\n",
    "    if i[-1] == \":\":\n",
    "        continue\n",
    "    preprocessed_line = preprocess_line(i)\n",
    "    corpus.append(preprocessed_line)\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-regular",
   "metadata": {},
   "source": [
    "### generate 'Token box' and fit on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advanced-valuation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x7f31e6941d10>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = 12000,\n",
    "                     oov_token = \"<OOV>\"\n",
    "                     )\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-species",
   "metadata": {},
   "source": [
    "### Vectorization : Change preprocessed lines to 'tensor'\n",
    "1)texts_to_sequences\n",
    "2)pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "worthy-century",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 67, 237, 4, 54, 658, 2], [3, 4, 54, 6475, 2], [3, 4, 1088, 528, 4, 100, 75, 201, 254, 6, 2], [3, 118, 12, 295, 34, 90, 4, 1125, 28, 297, 852, 2], [3, 33, 528, 74, 6, 87, 250, 11, 263, 2]]\n",
      "175749\n",
      "(175749, 15)\n"
     ]
    }
   ],
   "source": [
    "tensor = tokenizer.texts_to_sequences(corpus)\n",
    "print(tensor[:5])\n",
    "\n",
    "## 문장 token 15개 넘는 것 제거!\n",
    "\n",
    "for line in tensor:\n",
    "    if len(line) > 15:\n",
    "        line.pop()\n",
    "print(len(tensor))\n",
    "#padding도 간결하게!!\n",
    "\n",
    "tensor = pad_sequences(tensor,maxlen=15, padding = 'post')\n",
    "\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jewish-tobago",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <OOV>\n",
      "2 : end\n",
      "3 : start\n",
      "4 : i\n",
      "5 : the\n",
      "6 : you\n",
      "7 : and\n",
      "8 : a\n",
      "9 : to\n",
      "10 : it\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "packed-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3  67 237   4  54 658   2   0   0   0   0   0   0   0]\n",
      "[ 67 237   4  54 658   2   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-criticism",
   "metadata": {},
   "source": [
    "Step 4. 평가 데이터셋 분리\n",
    "훈련 데이터와 평가 데이터를 분리하세요!\n",
    "\n",
    "tokenize() 함수로 데이터를 Tensor로 변환한 후, sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리하도록 하겠습니다. 단어장의 크기는 12,000 이상 으로 설정하세요! 총 데이터의 20% 를 평가 데이터셋으로 사용해 주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "federal-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,tgt_input,\n",
    "    test_size = 0.2,\n",
    "    random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-malpractice",
   "metadata": {},
   "source": [
    "### Now, check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "curious-picnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (140599, 14)\n",
      "Target Train: (140599, 14)\n",
      "(35150, 14)\n",
      "(35150, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)\n",
    "print(enc_val.shape)\n",
    "print(dec_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-colony",
   "metadata": {},
   "source": [
    "out:\n",
    "\n",
    "Source Train: (124960, 14)\n",
    "Target Train: (124960, 14)\n",
    "\n",
    "만약 결과가 다르다면 천천히 과정을 다시 살펴 동일한 결과를 얻도록 하세요! 만약 학습 데이터 개수가 124960보다 크다면 위 Step 3.의 데이터 정제 과정을 다시 한번 검토해 보시기를 권합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-tournament",
   "metadata": {},
   "source": [
    "Step 5. 인공지능 만들기\n",
    "모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계하세요! (Loss는 아래 제시된 Loss 함수를 그대로 사용!)\n",
    "\n",
    "그리고 멋진 모델이 생성한 가사 한 줄을 제출하시길 바랍니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acknowledged-repair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 12001\n",
      "<BatchDataset shapes: ((1024, 14), (1024, 14)), types: (tf.int32, tf.int32)>\n",
      "<BatchDataset shapes: ((1024, 1024, 14), (1024, 1024, 14)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = enc_train.shape[0]\n",
    "BATCH_SIZE = 1024\n",
    "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words +1\n",
    "\n",
    "print(steps_per_epoch,VOCAB_SIZE)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)\n",
    "BUFFER_SIZE_2 = enc_val.shape[0]\n",
    "\n",
    "#print(BUFFER_SIZE_2)\n",
    "valset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "valset = dataset.shuffle(BUFFER_SIZE_2)\n",
    "valset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "harmful-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(0.2)\n",
    "        self.rnn_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size, return_sequences=True))\n",
    "        self.rnn_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size, return_sequences=True))\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(0.2)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.dropout_1(out)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.dropout_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "welcome-dispute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional multiple                  10493952  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection multiple                  25174016  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 63,330,273\n",
      "Trainable params: 63,330,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
    "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "\n",
    "model(src_sample)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "polyphonic-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "#Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "     from_logits=True, reduction='none')\n",
    "\n",
    "#loss = 'sparse_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "annual-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'my_checkpoint.ckpt'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             save_weights_only=True, \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fourth-parameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "137/137 [==============================] - 401s 3s/step - loss: 4.4256 - val_loss: 3.0157\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.01571, saving model to my_checkpoint.ckpt\n",
      "Epoch 2/10\n",
      "137/137 [==============================] - 398s 3s/step - loss: 2.2522 - val_loss: 0.6350\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.01571 to 0.63500, saving model to my_checkpoint.ckpt\n",
      "Epoch 3/10\n",
      "137/137 [==============================] - 397s 3s/step - loss: 0.4991 - val_loss: 0.2888\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63500 to 0.28878, saving model to my_checkpoint.ckpt\n",
      "Epoch 4/10\n",
      "137/137 [==============================] - 397s 3s/step - loss: 0.2076 - val_loss: 0.1824\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28878 to 0.18240, saving model to my_checkpoint.ckpt\n",
      "Epoch 5/10\n",
      "137/137 [==============================] - 396s 3s/step - loss: 0.1060 - val_loss: 0.1370\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18240 to 0.13703, saving model to my_checkpoint.ckpt\n",
      "Epoch 6/10\n",
      "137/137 [==============================] - 396s 3s/step - loss: 0.0609 - val_loss: 0.1164\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.13703 to 0.11637, saving model to my_checkpoint.ckpt\n",
      "Epoch 7/10\n",
      "137/137 [==============================] - 396s 3s/step - loss: 0.0386 - val_loss: 0.1056\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.11637 to 0.10557, saving model to my_checkpoint.ckpt\n",
      "Epoch 8/10\n",
      "137/137 [==============================] - 396s 3s/step - loss: 0.0254 - val_loss: 0.0987\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10557 to 0.09870, saving model to my_checkpoint.ckpt\n",
      "Epoch 9/10\n",
      "137/137 [==============================] - 396s 3s/step - loss: 0.0184 - val_loss: 0.0947\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09870 to 0.09466, saving model to my_checkpoint.ckpt\n",
      "Epoch 10/10\n",
      "137/137 [==============================] - 396s 3s/step - loss: 0.0135 - val_loss: 0.0919\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09466 to 0.09193, saving model to my_checkpoint.ckpt\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss, optimizer = optimizer)\n",
    "history = model.fit(dataset,validation_data=(enc_val, dec_val), batch_size = BATCH_SIZE, callbacks=[checkpoint], epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fourth-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    enc_val\n",
    "    end_token = tokenizer.word_index[\"end\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "geographic-baseball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f316c29eb90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aboriginal-china",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start i love you so much older older older la la la la la la la end '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love \", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-communication",
   "metadata": {},
   "source": [
    "### Finally, submit a line of lyrics the model generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-organization",
   "metadata": {},
   "source": [
    "i love you so much older older older la la la la la la la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-camping",
   "metadata": {},
   "source": [
    "## What i did for less loss\n",
    "### 1) adjusted batch size and hidden size\n",
    "### 2) Try to check the validation loss with checkpoint and print!\n",
    "### 3) Change model\n",
    "  - add bidirectional layer in RNN layer\n",
    "  - add 2 Dropout layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-clerk",
   "metadata": {},
   "source": [
    "## +Bonus, plot loss and val_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "younger-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = 10\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(np.arange(1,epochs + 1),history.history['loss'])\n",
    "plt.plot(np.arange(1,epochs + 1),history.history['val_loss'])\n",
    "plt.title('loss VS val_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-electronics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
